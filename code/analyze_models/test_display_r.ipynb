{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yessss\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "def path_link(path:str):\n",
    "    sys.path.append(path)\n",
    "\n",
    "path_link('master/code/lib')\n",
    "\n",
    "import dataLoading as dl\n",
    "from measure import plotStdMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PATH = 'master/code/runs1'\n",
    "#PATH = 'master/code/runs2'\n",
    "PATH = 'master/code/test_new_activation'\n",
    "\n",
    "#DISPLAY_PATH = 'master/code/display_l1'\n",
    "#DISPLAY_PATH = '/master/code/display_l1_2'\n",
    "DISPLAY_PATH = 'master/code/display_l1_test_new_activation'\n",
    "\n",
    "MODEL_PATH = 'master/code/models/mod_base'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findModels(path):\n",
    "    pathLists = []\n",
    "    for root, dirs, files in tqdm(os.walk(path)):\n",
    "            for file in files:\n",
    "                  \n",
    "                  if file.endswith('.pt'):\n",
    "                        pathLists.append(os.path.join(root, file))\n",
    "\n",
    "\n",
    "    return pathLists\n",
    "\n",
    "\n",
    "def delete_wandb_dirs(start_path):\n",
    "    for root, dirs, files in os.walk(start_path, topdown=False):\n",
    "        for dir_name in dirs:\n",
    "            if dir_name == \"wandb\":\n",
    "                dir_path = os.path.join(root, dir_name)\n",
    "                print(f\"Deleting: {dir_path}\")\n",
    "                shutil.rmtree(dir_path)\n",
    "\n",
    "\n",
    "def getLoader(path, batch_size = 32, shuffleBool = True, root = None, jsonFile = None, mode = 'training'):\n",
    "    datasetTraining = dl.DataLoader2(root, path = path, jsonFile = jsonFile, mode = mode)\n",
    "    loader = DataLoader(datasetTraining, batch_size=batch_size, shuffle = shuffleBool)\n",
    "    \n",
    "    return loader\n",
    "\n",
    "\n",
    "def getName(path):\n",
    "    run_name = path.split('/')[-3]\n",
    "\n",
    "    model_type = path.split('/')[-1].split('.')[0]\n",
    "\n",
    "    if 'best' in model_type:\n",
    "        model_type = '_best'\n",
    "\n",
    "    else:\n",
    "         model_type = '_latest'\n",
    "\n",
    "    name = run_name + model_type\n",
    "\n",
    "    return name\n",
    "\n",
    "\n",
    "def getModelName(key):\n",
    "\n",
    "    name = ''\n",
    "\n",
    "    #if 'simplest' in key:\n",
    "    #    name = name + 'simplest'\n",
    "    \n",
    "    name = name + 'simplest'\n",
    "\n",
    "    ## other possibilities\n",
    "\n",
    "    if 'no-dropout' in key:\n",
    "        name = name + '_no-dropout'\n",
    "    else:\n",
    "        name = name + '_dropout'\n",
    "\n",
    "    if 'no-encoder' in key:\n",
    "        name = name + '_no-encoder'\n",
    "    else:\n",
    "        name = name + '_encoder'\n",
    "\n",
    "    if 'relu' in key:\n",
    "        name = name + '-relu'\n",
    "\n",
    "    return name\n",
    "         \n",
    "\n",
    "def loadModel(modelName:str, inputShape:int = 8, edges_shape = 5, path = None):\n",
    "    \"\"\" \n",
    "    Function to import the model\n",
    "\n",
    "    Args:\n",
    "    -----\n",
    "        - `modelName`: name of the model\n",
    "        - `inputShape`: inout shape of the NN\n",
    "        - `edges_shape`: edge shape of the NN\n",
    "        - `path`: path where the models are\n",
    "    \"\"\"\n",
    "\n",
    "    sys.path.append(path)\n",
    "\n",
    "    loadFun = __import__(f'{modelName}', fromlist = ('loadNetwork'))\n",
    "\n",
    "    model = loadFun.loadNetwork(inputShape, edges_shape)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "def findLoader(key):\n",
    "\n",
    "    # remains initial conditions to consider\n",
    "    if 'normal' in key:\n",
    "        if '0_01' in key:\n",
    "            dataloader_path = '/master/code/simulation/path/mew_0_01_normal.json'\n",
    "\n",
    "        else:       # 0.001\n",
    "            dataloader_path = '/master/code/simulation/path/mew_0_001_normal.json'\n",
    "\n",
    "    else:       # noisy\n",
    "        if '0_01' in key:\n",
    "            dataloader_path = '/master/code/simulation/path/mew_0_01_noisy.json'\n",
    "\n",
    "        else:       # 0.001\n",
    "            dataloader_path = '/master/code/simulation/path/mew_0_001_noisy.json'\n",
    "\n",
    "    print(dataloader_path)\n",
    "\n",
    "\n",
    "    return getLoader(None, 128, True, None, dataloader_path, 'test')\n",
    "\n",
    "\n",
    "def getOrderedVals(attribute, message, bins):\n",
    "    bin_edges = np.linspace(np.min(attribute), np.max(attribute), bins + 1)\n",
    "    bin_indices = np.digitize(attribute, bin_edges) - 1\n",
    "\n",
    "    means = np.zeros(bins)\n",
    "    stds = np.zeros(bins)\n",
    "\n",
    "    for i in range(bins):\n",
    "        bin_mask = bin_indices == i\n",
    "        if np.any(bin_mask):\n",
    "            means[i] = np.mean(message[bin_mask])\n",
    "            stds[i] = np.std(message[bin_mask])\n",
    "        else:\n",
    "            means[i] = np.nan\n",
    "            stds[i] = np.nan\n",
    "\n",
    "    bin_centers = (bin_edges[:-1] + bin_edges[1:]) / 2\n",
    "\n",
    "\n",
    "    return bin_centers, means, stds\n",
    "\n",
    "\n",
    "\n",
    "def findIndices(message, nb = 5):\n",
    "    stdv=plotStdMessage(message)\n",
    "    plt.close()\n",
    "\n",
    "    inds = np.argsort(stdv)\n",
    "\n",
    "    return inds[-nb:]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def plotMessage(graph, messages, i_attr, id_message):\n",
    "    edges = graph.edge_attr.cpu().detach().numpy().copy()\n",
    "    x, mean, std = getOrderedVals(edges[:, i_attr], messages[:, id_message], 100)\n",
    "    plt.scatter(edges[:, i_attr], messages[:, id_message])\n",
    "    #plt.plot(x, mean, 'green')\n",
    "    #plt.fill_between(x, mean-std, mean+ std, color = 'red', alpha = 0.4)\n",
    "    #plt.vlines(x = 2, ymin = np.min(messages[:, id]), ymax = np.max(messages[:, id]))\n",
    "    #plt.vlines(x = 4, ymin = np.min(messages[:, id]), ymax = np.max(messages[:, id]))\n",
    "\n",
    "\n",
    "def plotMessageEvol(modelList, pathPlot = DISPLAY_PATH):\n",
    "\n",
    "    # create folders\n",
    "\n",
    "    out_poss = ['distance', 'cosine', 'sine', 'radius_1', 'radius_2']\n",
    "    number_messages = 5\n",
    "    \n",
    "    nb = 0\n",
    "    nb_sim = 0\n",
    "    with torch.no_grad():\n",
    "        # get the data for the different models\n",
    "\n",
    "        for model_path in tqdm(modelList):\n",
    "            nb_sim += 1\n",
    "\n",
    "            # path for the experiment\n",
    "            p_exp = os.path.join(pathPlot, f'exp_{nb_sim}')\n",
    "            if not os.path.exists(p_exp):\n",
    "                os.makedirs(p_exp)\n",
    "            else:\n",
    "                print('WARNING: weird stuff here')\n",
    "\n",
    "            for f in out_poss:\n",
    "                p = os.path.join(p_exp, f)\n",
    "                if not os.path.exists(p):\n",
    "                    os.makedirs(p)\n",
    "\n",
    "            # find name that identify the model\n",
    "            name_plot = getName(model_path)\n",
    "\n",
    "            # load model\n",
    "            try:\n",
    "                model = loadModel(getModelName(name_plot), path=MODEL_PATH)\n",
    "                std_dict = torch.load(model_path)\n",
    "                model.load_state_dict(std_dict)\n",
    "                model.eval()\n",
    "\n",
    "                # condition loader on the dt\n",
    "                loader = findLoader(model_path)\n",
    "\n",
    "                # get data\n",
    "                for data, _ in loader:\n",
    "                    break\n",
    "\n",
    "                # get messages\n",
    "                message = model.message(data).cpu().detach().numpy()\n",
    "\n",
    "\n",
    "\n",
    "                # best messages indices\n",
    "                inds = findIndices(message, nb = number_messages)\n",
    "\n",
    "                plotStdMessage(message.copy())\n",
    "                p_std = os.path.join(p_exp, f'{name_plot}.png')\n",
    "                if os.path.exists(p_std):\n",
    "                    print(\"WARNING >>> issue here\")\n",
    "                plt.savefig(p_std)\n",
    "                plt.close()\n",
    "\n",
    "                for i in range(len(out_poss)):      # radius, ...\n",
    "                    for j in range(number_messages):    # id of the message\n",
    "\n",
    "                        plotMessage(data, message.copy(), i, inds[j])\n",
    "                        \n",
    "                        path = os.path.join(p_exp, out_poss[i])\n",
    "                        path = os.path.join(path, f\"{name_plot}_attr-{out_poss[i]}_nb-{j}.png\")\n",
    "\n",
    "                        nb_plot = 0\n",
    "                        while os.path.exists(path):\n",
    "                            nb_plot += 1\n",
    "                            path = os.path.join(p_exp, out_poss[i])\n",
    "                            path = os.path.join(path, f\"{name_plot}_attr-{out_poss[i]}_nb-{j}_nbPlot-{nb_plot}.png\")\n",
    "\n",
    "                        plt.savefig(path)\n",
    "                        plt.close()\n",
    "\n",
    "            except:\n",
    "                print(f'Issue >>> {nb}')\n",
    "                nb += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "model_list = findModels('/master/code/analyze_models/exp/test_new_activation_0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(os.path.exists('/master/code/analyze_models/exps/test_new_activation_0'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>> loading simplest\n",
      "INFO >>> relu end of message MLP\n",
      "INFO >>> with DROPOUT\n",
      "INFO >>> with NO encoder\n",
      "/master/code/simulation/path/mew_0_001_normal.json\n",
      "WARNING >>> issue here\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 1/6 [00:13<01:09, 13.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>> loading simplest\n",
      "INFO >>> relu end of message MLP\n",
      "INFO >>> with DROPOUT\n",
      "INFO >>> with NO encoder\n",
      "/master/code/simulation/path/mew_0_001_normal.json\n",
      "WARNING >>> issue here\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 2/6 [00:30<01:02, 15.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>> loading simplest\n",
      "INFO >>> relu end of message MLP\n",
      "INFO >>> with DROPOUT\n",
      "INFO >>> with NO encoder\n",
      "/master/code/simulation/path/mew_0_001_normal.json\n",
      "WARNING >>> issue here\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 3/6 [00:44<00:44, 14.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>> loading simplest\n",
      "INFO >>> relu end of message MLP\n",
      "INFO >>> with DROPOUT\n",
      "INFO >>> with NO encoder\n",
      "/master/code/simulation/path/mew_0_001_normal.json\n",
      "WARNING >>> issue here\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 4/6 [01:01<00:31, 15.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>> loading simplest\n",
      "INFO >>> relu end of message MLP\n",
      "INFO >>> with NO encoder\n",
      "INFO >>> with NO dropout\n",
      "/master/code/simulation/path/mew_0_001_normal.json\n",
      "WARNING >>> issue here\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 5/6 [01:14<00:14, 14.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>> loading simplest\n",
      "INFO >>> relu end of message MLP\n",
      "INFO >>> with NO encoder\n",
      "INFO >>> with NO dropout\n",
      "/master/code/simulation/path/mew_0_001_normal.json\n",
      "WARNING >>> issue here\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [01:31<00:00, 15.24s/it]\n"
     ]
    }
   ],
   "source": [
    "plotMessageEvol(model_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear regression analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simulation import calculate_interaction\n",
    "\n",
    "EPSILON = ...\n",
    "K = ...\n",
    "RADII = 1\n",
    "\n",
    "\n",
    "def getGTMessages(graph, epsilon = EPSILON, k = K, radii = RADII):\n",
    "\n",
    "    ri = graph.x[graph.edge_inds[0, :], :2].cpu().detach().numpy()\n",
    "    rj = graph.x[graph.edge_inds[1, :], :2].cpu().detach().numpy()\n",
    "\n",
    "    N = graph.x.shape[0]\n",
    "\n",
    "    forces = calculate_interaction(N, ri, rj, k, epsilon, radii = 1.0)\n",
    "\n",
    "    return forces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMessage(graph, model):\n",
    "    message = model.message(graph).cpu().detach().numpy()\n",
    "    return message\n",
    "\n",
    "## analyser les dimensions pour savoir quel message correspond a quoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSim():\n",
    "    lim = 0.85 * 100\n",
    "\n",
    "    xPos = np.linspace(-lim, lim, 10)\n",
    "    yPos = np.linspace(-lim, lim, 10)\n",
    "    gridX, gridY = np.meshgrid(xPos, yPos)\n",
    "    delta = np.random.uniform(0, 7, gridX.shape + (2,))\n",
    "\n",
    "    gridX2 = gridX + delta[:, :, 0]\n",
    "    gridY2 = gridY + delta[:, :, 1]\n",
    "\n",
    "    pos = np.stack([gridX.ravel(), gridY.ravel()], axis=1)\n",
    "    pos_perturbed = np.stack([gridX2.ravel(), gridY2.ravel()], axis=1)\n",
    "\n",
    "    pos = np.concatenate([pos, pos_perturbed], axis=0)\n",
    "\n",
    "    angles = np.random.rand(pos.shape[0]) * 2 * np.pi\n",
    "\n",
    "    data = sim.compute_main(200, (60, 3.5, 70, 0.5), 120, T = 200, initialization = (pos, angles), dt = 0.001)[0]\n",
    "\n",
    "    x, y, attr, inds = ft.processSimulation(data)\n",
    "\n",
    "    return x, y, attr, inds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "def getLinearComp(model):\n",
    "\n",
    "    # get data\n",
    "    data = getSim()\n",
    "    inds = np.arange(data.shape[0])\n",
    "    random.shuffle(inds)\n",
    "    inds = inds[:5]\n",
    "    graphs = data[inds]\n",
    "\n",
    "    gt = None\n",
    "    messages = None\n",
    "\n",
    "    for graph in graphs:\n",
    "\n",
    "        graph = None\n",
    "        # get the gt messages and the predicted messages\n",
    "\n",
    "        if gt is None:\n",
    "            gt = getGTMessages(graph)\n",
    "            messages = getMessage(graph, model)\n",
    "        else:\n",
    "            gt = np.vstack((gt, getGTMessages(graph)))\n",
    "            messages = np.vstack((messages, getMessage(graph, model)))\n",
    "\n",
    "\n",
    "    # fit a linear model\n",
    "    # MAKE 2 models if need to dissociate the two (should be fine though)\n",
    "    mod = LinearRegression()\n",
    "    mod.fit(messages, gt)\n",
    "\n",
    "\n",
    "    # get new data\n",
    "    data = getSim()\n",
    "    inds = np.arange(data.shape[0])\n",
    "    random.shuffle(inds)\n",
    "    inds = inds[:5]\n",
    "    graphs = data[inds]\n",
    "\n",
    "    graph = None\n",
    "\n",
    "    gt = None\n",
    "    preds = None\n",
    "\n",
    "    for graph in graphs:\n",
    "        # get the new gt and predicted messages\n",
    "\n",
    "        if gt is None:\n",
    "            gt = getGTMessages(graph)\n",
    "            messages = getMessage(graph, model)\n",
    "            preds = model.predict(messages)\n",
    "\n",
    "        else:\n",
    "            gt = np.vstack((gt, getGTMessages(graph)))\n",
    "            messages = getMessage(graph, model)\n",
    "\n",
    "            preds = np.vstack((preds, model.predict(messages)))\n",
    "\n",
    "    r2 = r2_score(gt, preds)\n",
    "\n",
    "    return r2, preds, gt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get data into a csv dataframe for the errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combinePandas(df1, df2):\n",
    "\n",
    "    combined_columns = df1.columns.union(df2.columns)\n",
    "    df1 = df1.reindex(columns=combined_columns, fill_value=0)\n",
    "    df2 = df2.reindex(columns=combined_columns, fill_value=0)\n",
    "    \n",
    "    combined_df = pd.concat([df1, df2], ignore_index=True)\n",
    "    \n",
    "    return combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   A  B\n",
      "0  1  3\n",
      "1  2  4\n",
      "\n",
      "\n",
      "   B  C\n",
      "0  5  7\n",
      "1  6  8\n",
      "\n",
      "\n",
      "   A  B  C\n",
      "0  1  3  0\n",
      "1  2  4  0\n",
      "2  0  5  7\n",
      "3  0  6  8\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Example DataFrames\n",
    "df1 = pd.DataFrame({\n",
    "    'A': [1, 2],\n",
    "    'B': [3, 4]\n",
    "})\n",
    "\n",
    "df2 = pd.DataFrame({\n",
    "    'B': [5, 6],\n",
    "    'C': [7, 8]\n",
    "})\n",
    "\n",
    "# Combine the DataFrames\n",
    "combined_df = combinePandas(df1, df2)\n",
    "print(df1)\n",
    "print('\\n')\n",
    "print(df2)\n",
    "print('\\n')\n",
    "print(combined_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

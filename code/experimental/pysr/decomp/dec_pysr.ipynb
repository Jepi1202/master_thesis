{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "import shutil\n",
    "import json\n",
    "\n",
    "def path_link(path:str):\n",
    "    sys.path.append(path)\n",
    "\n",
    "path_link('/master/code/lib')\n",
    "\n",
    "import dataLoading as dl\n",
    "from measure import plotStdMessage\n",
    "import simulation_v2 as sim\n",
    "import features as ft\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################\n",
    "# paths \n",
    "\n",
    "#PATH = 'master/code/runs1'\n",
    "#PATH = 'master/code/runs2'\n",
    "#PATH = ['/master/code/analyze_models/exps/test_new_activation_0']\n",
    "PATH = ['/master/code/analyze_models/exps/exp-test']\n",
    "\n",
    "#DISPLAY_PATH = 'master/code/display_l1'\n",
    "#DISPLAY_PATH = '/master/code/display_l1_2'\n",
    "#DISPLAY_PATH = ['/master/code/analyze_models/display2/test_new_activation_0']\n",
    "DISPLAY_PATH = ['/master/code/analyze_models/display-dec/exp-test']\n",
    "\n",
    "MODEL_PATH = '/master/code/models/mod_base'\n",
    "\n",
    "\n",
    "##############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "limits = [[0, 2], [2, 3], [3, 4], [4, 10]]\n",
    "delta = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Parameters():\n",
    "    def __init__(self):\n",
    "        self.dt = 0.001\n",
    "        self.v0 = 60\n",
    "        self.k = 70\n",
    "        self.epsilon = 0.5\n",
    "        self.tau = 3.5\n",
    "        self.R = 1\n",
    "        self.N = 200\n",
    "        self.boundary = 100\n",
    "\n",
    "        self.nbStep = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findModels(path):\n",
    "    pathLists = []\n",
    "    for root, dirs, files in tqdm(os.walk(path)):\n",
    "            for file in files:\n",
    "                  \n",
    "                  if file.endswith('.pt'):\n",
    "                        pathLists.append(os.path.join(root, file))\n",
    "\n",
    "\n",
    "    return pathLists\n",
    "\n",
    "\n",
    "def delete_wandb_dirs(start_path):\n",
    "    for root, dirs, files in os.walk(start_path, topdown=False):\n",
    "        for dir_name in dirs:\n",
    "            if dir_name == \"wandb\":\n",
    "                dir_path = os.path.join(root, dir_name)\n",
    "                print(f\"Deleting: {dir_path}\")\n",
    "                shutil.rmtree(dir_path)\n",
    "\n",
    "\n",
    "\n",
    "def getName(path):\n",
    "    run_name = path.split('/')[-3]\n",
    "\n",
    "    model_type = path.split('/')[-1].split('.')[0]\n",
    "\n",
    "    if 'best' in model_type:\n",
    "        model_type = '_best'\n",
    "\n",
    "    else:\n",
    "         model_type = '_latest'\n",
    "\n",
    "    name = run_name + model_type\n",
    "\n",
    "    return name\n",
    "\n",
    "\n",
    "def loadModel(modelName:str, inputShape:int = 8, edges_shape = 5, path = None):\n",
    "    \"\"\" \n",
    "    Function to import the model\n",
    "\n",
    "    Args:\n",
    "    -----\n",
    "        - `modelName`: name of the model\n",
    "        - `inputShape`: inout shape of the NN\n",
    "        - `edges_shape`: edge shape of the NN\n",
    "        - `path`: path where the models are\n",
    "    \"\"\"\n",
    "\n",
    "    sys.path.append(path)\n",
    "\n",
    "    loadFun = __import__(f'{modelName}', fromlist = ('loadNetwork'))\n",
    "\n",
    "    model = loadFun.loadNetwork(inputShape, edges_shape)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "def getModelName(key):\n",
    "\n",
    "    name = ''\n",
    "\n",
    "    #if 'simplest' in key:\n",
    "    #    name = name + 'simplest'\n",
    "    \n",
    "    name = name + 'simplest'\n",
    "\n",
    "    ## other possibilities\n",
    "\n",
    "    if 'no-dropout' in key:\n",
    "        name = name + '_no-dropout'\n",
    "    else:\n",
    "        name = name + '_dropout'\n",
    "\n",
    "    if 'no-encoder' in key:\n",
    "        name = name + '_no-encoder'\n",
    "    else:\n",
    "        name = name + '_encoder'\n",
    "\n",
    "    if 'relu' in key:\n",
    "        name = name + '-relu'\n",
    "\n",
    "    return name\n",
    "\n",
    "\n",
    "##############################\n",
    "# Messages\n",
    "#TODO linear \n",
    "\n",
    "\n",
    "def getOrderedVals(attribute, message, bins):\n",
    "    bin_edges = np.linspace(np.min(attribute), np.max(attribute), bins + 1)\n",
    "    bin_indices = np.digitize(attribute, bin_edges) - 1\n",
    "\n",
    "    means = np.zeros(bins)\n",
    "    stds = np.zeros(bins)\n",
    "\n",
    "    for i in range(bins):\n",
    "        bin_mask = bin_indices == i\n",
    "        if np.any(bin_mask):\n",
    "            means[i] = np.mean(message[bin_mask])\n",
    "            stds[i] = np.std(message[bin_mask])\n",
    "        else:\n",
    "            means[i] = np.nan\n",
    "            stds[i] = np.nan\n",
    "\n",
    "    bin_centers = (bin_edges[:-1] + bin_edges[1:]) / 2\n",
    "\n",
    "\n",
    "    return bin_centers, means, stds\n",
    "\n",
    "\n",
    "def findIndices(message, nb = 5):\n",
    "    stdv=plotStdMessage(message)\n",
    "    plt.close()\n",
    "\n",
    "    inds = np.argsort(stdv)\n",
    "    # change of the order\n",
    "    return np.flip(inds[-nb:])\n",
    "\n",
    "\n",
    "def plotMessage(graph, messages, i_attr, id_message):\n",
    "    edges = None\n",
    "    \n",
    "    for i in range(len(graph)):\n",
    "        if edges is None:\n",
    "            edges = graph[i].edge_attr.cpu().detach().numpy().copy()\n",
    "        else:\n",
    "            edges = np.vstack((edges, graph[i].edge_attr.cpu().detach().numpy().copy()))\n",
    "\n",
    "    x, mean, std = getOrderedVals(edges[:, i_attr], messages[:, id_message], 100)\n",
    "    plt.scatter(edges[:, i_attr], messages[:, id_message])\n",
    "\n",
    "\n",
    "def calculate_interaction(dist, rij, k, epsilon, radii = 1.0):\n",
    "    \"\"\"\n",
    "    Given the vectors ri and rj, compute the force between them\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    r = dist\n",
    "\n",
    "    # Combined radius of both particles (assume unit radii for now)\n",
    "    #bij = 2.0                       # Ri + Rj \n",
    "    bij = radii + radii\n",
    "\n",
    "    if r < bij*(1 + epsilon):\n",
    "        force = k*(r - bij)*rij/r  \n",
    "    elif r < bij*(1 + 2*epsilon):\n",
    "        force = -k*(r - bij - 2*epsilon*bij)*rij/r\n",
    "    else:\n",
    "        force = torch.tensor([0.0, 0.0])\n",
    "    return force"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getData(params):\n",
    "    N = params.N\n",
    "    v0 = params.v0\n",
    "    k = params.k\n",
    "    eps = params.epsilon\n",
    "    tau = params.tau\n",
    "    R = params.R\n",
    "    dt = params.dt\n",
    "    nbStep = params.nbStep\n",
    "    boundary = params.boundary\n",
    "\n",
    "    lim = 0.85 * 100\n",
    "\n",
    "    xPos = np.linspace(-lim, lim, 10)\n",
    "    yPos = np.linspace(-lim, lim, 10)\n",
    "    gridX, gridY = np.meshgrid(xPos, yPos)\n",
    "    delta = np.random.uniform(0, 7, gridX.shape + (2,))\n",
    "\n",
    "    gridX2 = gridX + delta[:, :, 0]\n",
    "    gridY2 = gridY + delta[:, :, 1]\n",
    "\n",
    "    pos = np.stack([gridX.ravel(), gridY.ravel()], axis=1)\n",
    "    pos_perturbed = np.stack([gridX2.ravel(), gridY2.ravel()], axis=1)\n",
    "\n",
    "    pos = np.concatenate([pos, pos_perturbed], axis=0)\n",
    "\n",
    "    angles = np.random.rand(pos.shape[0]) * 2 * np.pi\n",
    "\n",
    "    data = sim.compute_main(N, (v0, tau, k, eps), boundary, T = nbStep, initialization = (pos, angles), dt = dt)[0]\n",
    "\n",
    "    x, y, attr, inds = ft.processSimulation(data)\n",
    "\n",
    "    dataList = []\n",
    "\n",
    "    for i in range(len(x)):\n",
    "        g = Data(x = x[i][:, 2:], y = y[i], edge_attr = attr[i], edge_index = inds[i])\n",
    "        dataList.append(g)\n",
    "\n",
    "    return dataList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLoader(path, batch_size = 32, shuffleBool = True, root = None, jsonFile = None, mode = 'training'):\n",
    "    datasetTraining = dl.DataLoader2(root, path = path, jsonFile = jsonFile, mode = mode)\n",
    "    loader = DataLoader(datasetTraining, batch_size=batch_size, shuffle = shuffleBool)\n",
    "    \n",
    "    return loader\n",
    "\n",
    "\n",
    "def findLoader(key):\n",
    "\n",
    "    # remains initial conditions to consider\n",
    "\n",
    "    if 'normal' in key:\n",
    "        if '0_01' in key:\n",
    "            dataloader_path = '/master/code/simulation/path/mew_0_01_normal.json'\n",
    "\n",
    "        else:       # 0.001\n",
    "            dataloader_path = '/master/code/simulation/path/mew_0_001_normal.json'\n",
    "\n",
    "    else:       # noisy\n",
    "        if '0_01' in key:\n",
    "            dataloader_path = '/master/code/simulation/path/mew_0_01_noisy.json'\n",
    "\n",
    "        else:       # 0.001\n",
    "            dataloader_path = '/master/code/simulation/path/mew_0_001_noisy.json'\n",
    "\n",
    "\n",
    "    print(f'>>>> HARDCODED loader')\n",
    "    dataloader_path = '/master/code/simulation/path/mew_0_001_normal.json'\n",
    "\n",
    "    print(dataloader_path)\n",
    "\n",
    "\n",
    "    return getLoader(None, 128, True, None, dataloader_path, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decomposeData(graph, messages, limits, delta, res = None):\n",
    "\n",
    "    if res is None:\n",
    "        res = {}\n",
    "\n",
    "        for l in limits:\n",
    "\n",
    "            res[f'{l[0]}-{l[1]}'] = {}\n",
    "            res[f'{l[0]}-{l[1]}']['attr']= []\n",
    "            res[f'{l[0]}-{l[1]}']['messages']= []\n",
    "            res[f'{l[0]}-{l[1]}']['nodes']= []\n",
    "\n",
    "\n",
    "    attr = graph.edge_attr\n",
    "    inds = graph.edge_index\n",
    "    nodes = graph.x\n",
    "\n",
    "    for i in range(attr.shape[0]):\n",
    "        dist = attr[i][0]\n",
    "\n",
    "        for l in limits:\n",
    "            l1 = l[0] + delta\n",
    "            l2 = l[1] - delta\n",
    "        \n",
    "\n",
    "            if dist > l1 and dist < l2:\n",
    "                res[f'{l[0]}-{l[1]}']['attr'].append(attr[i, :].cpu().detach().numpy().tolist())\n",
    "                res[f'{l[0]}-{l[1]}']['messages'].append(messages[i, :].tolist())\n",
    "                res[f'{l[0]}-{l[1]}']['nodes'].append(nodes[inds[0, i], :].cpu().detach().numpy().tolist())\n",
    "\n",
    "\n",
    "\n",
    "    return res\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readJson(filePath:str):\n",
    "    \"\"\"\n",
    "    Function to read json \n",
    "    \"\"\"\n",
    "    \n",
    "    with open(filePath, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    return data\n",
    "\n",
    "\n",
    "def writeJson(data, filePath):\n",
    "    \"\"\"\n",
    "    Function to write json \n",
    "    \"\"\"\n",
    "    with open(filePath, 'w') as f:\n",
    "        json.dump(data, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/master/code/analyze_models/display-dec/exp-test']\n"
     ]
    }
   ],
   "source": [
    "print(DISPLAY_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decomp_main(modelList, pathPlot = DISPLAY_PATH):\n",
    "\n",
    "    number_messages=2\n",
    "    nb_sim = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # get the data for the different models\n",
    "\n",
    "        for model_path in tqdm(modelList):\n",
    "            nb_sim += 1\n",
    "\n",
    "            # path for the experiment\n",
    "            p_exp = os.path.join(pathPlot, f'exp_{nb_sim}')\n",
    "            if not os.path.exists(p_exp):\n",
    "                os.makedirs(p_exp)\n",
    "            else:\n",
    "                print('WARNING: weird stuff here')\n",
    "\n",
    "\n",
    "            name_plot = getName(model_path)\n",
    "\n",
    "\n",
    "            #try:\n",
    "            model = loadModel(getModelName(name_plot), path=MODEL_PATH)\n",
    "            std_dict = torch.load(model_path)\n",
    "            model.load_state_dict(std_dict)\n",
    "            model.eval()\n",
    "\n",
    "            # condition loader on the dt\n",
    "            loader = findLoader(model_path)\n",
    "\n",
    "            # get data\n",
    "            for data, _ in loader:\n",
    "                break\n",
    "\n",
    "            print(data)\n",
    "\n",
    "            # get messages\n",
    "            message = model.message(data).cpu().detach().numpy()\n",
    "\n",
    "\n",
    "            inds = findIndices(message, nb = number_messages)\n",
    "\n",
    "\n",
    "            d = decomposeData(data, message[:, inds], limits, delta, res = None)\n",
    "\n",
    "            writeJson(d, os.path.join(p_exp, 'data.json'))\n",
    "\n",
    "            #except:\n",
    "            #    print(f'Issue {nb_sim}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:00, 32.34it/s]\n"
     ]
    }
   ],
   "source": [
    "if PATH is None:\n",
    "    # check if listdir only outputs the last element (...)\n",
    "    list_exp = [os.listdir('/master/code/analyze_models/exp/')]\n",
    "    list_disp = [os.path.join('/master/code/analyze_models/display2', list_exp[i]) for i in range(len(list_exp))]\n",
    "\n",
    "else:\n",
    "    list_exp = PATH\n",
    "    list_disp = DISPLAY_PATH\n",
    "\n",
    "\n",
    "for i in range(len(list_exp)):\n",
    "\n",
    "    exp = list_exp[i]\n",
    "    disp = list_disp[i]\n",
    "\n",
    "    model_list = findModels(exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/master/code/analyze_models/exps/exp-test/test_new_activation/master-thesis_normal_classic_dt-0.01_lr-0.001_batch-16_encoder-no-encoder_dropout-no-dropout-exp/model_trained/simplest_no-dropout_no-encoder_aug_best_0-001-test.pt\n"
     ]
    }
   ],
   "source": [
    "print(model_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: weird stuff here\n",
      ">>>> loading simplest\n",
      "INFO >>> with NO encoder\n",
      "INFO >>> with NO dropout\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>> HARDCODED loader\n",
      "/master/code/simulation/path/mew_0_001_normal.json\n",
      "DataBatch(x=[38400, 10], edge_index=[2, 76536], edge_attr=[76536, 5], y=[38400, 10, 2], batch=[38400], ptr=[129])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [00:18<00:18, 18.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: weird stuff here\n",
      ">>>> loading simplest\n",
      "INFO >>> with NO encoder\n",
      "INFO >>> with NO dropout\n",
      ">>>> HARDCODED loader\n",
      "/master/code/simulation/path/mew_0_001_normal.json\n",
      "DataBatch(x=[38400, 10], edge_index=[2, 74710], edge_attr=[74710, 5], y=[38400, 10, 2], batch=[38400], ptr=[129])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:43<00:00, 21.76s/it]\n"
     ]
    }
   ],
   "source": [
    "decomp_main(model_list, pathPlot = DISPLAY_PATH[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

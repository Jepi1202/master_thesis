{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def path_link(path:str):\n",
    "    sys.path.append(path)\n",
    "\n",
    "path_link('master/code/lib')\n",
    "\n",
    "import features as ft\n",
    "import simulation as sim \n",
    "#import simulation_2 as sim2\n",
    "#import simulation_3 as sim3\n",
    "import NNSimulator as nnsim\n",
    "#import NNSimulator_2 as nnsim2\n",
    "import display as disp\n",
    "\n",
    "from norm import normalizeCol\n",
    "\n",
    "\n",
    "PATH_MODEL = 'master/code/models/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadModel(modelName:str, inputShape:int = 9, edges_shape = 3, path = PATH_MODEL):\n",
    "    \"\"\" \n",
    "    Function to import the model\n",
    "\n",
    "    Args:\n",
    "    -----\n",
    "        - `modelName`: name of the model\n",
    "        - `inputShape`: inout shape of the NN\n",
    "        - `edges_shape`: edge shape of the NN\n",
    "        - `path`: path where the models are\n",
    "    \"\"\"\n",
    "\n",
    "    sys.path.append(path)\n",
    "\n",
    "    loadFun = __import__(f'{modelName}', fromlist = ('loadNetwork'))\n",
    "\n",
    "    model = loadFun.loadNetwork(inputShape, edges_shape)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v0:60, tau:3.5, k:70, epsilon:0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 450/450 [00:02<00:00, 192.60it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "only integer scalar arrays can be converted to a scalar index",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# get speeds\u001b[39;00m\n\u001b[1;32m      6\u001b[0m v \u001b[38;5;241m=\u001b[39m ft\u001b[38;5;241m.\u001b[39mgetSpeeds(data)\n\u001b[0;32m----> 8\u001b[0m mat \u001b[38;5;241m=\u001b[39m \u001b[43mft\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetFeatures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m featuresData \u001b[38;5;241m=\u001b[39m mat[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;28mid\u001b[39m]\n\u001b[1;32m     12\u001b[0m nextState \u001b[38;5;241m=\u001b[39m mat[\u001b[38;5;241m1\u001b[39m][\u001b[38;5;28mid\u001b[39m]\n",
      "File \u001b[0;32m/master/code/lib/features.py:178\u001b[0m, in \u001b[0;36mgetFeatures\u001b[0;34m(mat, nb)\u001b[0m\n\u001b[1;32m    174\u001b[0m     yB\u001b[38;5;241m.\u001b[39mappend(y[i])\n\u001b[1;32m    177\u001b[0m \u001b[38;5;66;03m# features\u001b[39;00m\n\u001b[0;32m--> 178\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mgetSpeedFeatures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[38;5;66;03m# add the parameters\u001b[39;00m\n\u001b[1;32m    181\u001b[0m \u001b[38;5;66;03m#x = addParams(x, params)    \u001b[39;00m\n\u001b[1;32m    183\u001b[0m vectnodes \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m/master/code/lib/features.py:114\u001b[0m, in \u001b[0;36mgetSpeedFeatures\u001b[0;34m(mat, nb)\u001b[0m\n\u001b[1;32m    108\u001b[0m speeds \u001b[38;5;241m=\u001b[39m getSpeeds(mat)\n\u001b[1;32m    110\u001b[0m \u001b[38;5;66;03m# uncomment following to activate speed norms\u001b[39;00m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;66;03m#speedNorms = np.sqrt(speeds[:, :, 0] ** 2 + speeds[:, :, 1] ** 2)\u001b[39;00m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;66;03m#speeds = np.concatenate((speeds, speedNorms[:, :, np.newaxis]), axis = -1)\u001b[39;00m\n\u001b[0;32m--> 114\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnb\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    115\u001b[0m     s \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((mat\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], mat\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], speeds\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]))\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[0;31mTypeError\u001b[0m: only integer scalar arrays can be converted to a scalar index"
     ]
    }
   ],
   "source": [
    "# generate a simulation\n",
    "data = sim.compute_main(100, (60, 3.5, 70, 0.5), 120, T = 450)[0]\n",
    "id = 0\n",
    "\n",
    "# get speeds\n",
    "v = ft.getSpeeds(data)\n",
    "\n",
    "mat = ft.getFeatures(data, np.array([0.1]))\n",
    "\n",
    "featuresData = mat[0][id]\n",
    "\n",
    "nextState = mat[1][id]\n",
    "\n",
    "edge_ind, edge_atr = ft.getEdges(data)\n",
    "\n",
    "edge_ind = edge_ind[id]\n",
    "edge_atr = edge_atr[id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_atr = normalizeCol(edge_atr, -8, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "inds = np.arange(data.shape[0]-1-5) + 5\n",
    "import torch\n",
    "speeds = torch.from_numpy(data[inds+1, :, :] - data[inds, :, :]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = loadModel('model_gt')\n",
    "\n",
    "#res  = nnsim2.getSimulationData(mod, 450, data, i = 5, display =True, train = True).detach().cpu().numpy()\n",
    "res1  = nnsim2.getSimulationData(mod, 300, data, i = 5, debug =speeds.clone(), train = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/450 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'Tensor' and 'Data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mnnsim2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetSimulationData\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m450\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdisplay\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "File \u001b[0;32m/master/code/lib/NNSimulator_2.py:235\u001b[0m, in \u001b[0;36mgetSimulationData\u001b[0;34m(model, nbTimesteps, d, i, display, train, debug)\u001b[0m\n\u001b[1;32m    232\u001b[0m attr \u001b[38;5;241m=\u001b[39m normalizeCol(attr, MIN_DELTA, MAX_DELTA)\n\u001b[1;32m    233\u001b[0m s \u001b[38;5;241m=\u001b[39m Data(x \u001b[38;5;241m=\u001b[39m x[\u001b[38;5;241m4\u001b[39m][: , \u001b[38;5;241m2\u001b[39m:], edge_attr \u001b[38;5;241m=\u001b[39m attr, edge_index \u001b[38;5;241m=\u001b[39m inds)\u001b[38;5;241m.\u001b[39mto(DEVICE)\n\u001b[0;32m--> 235\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mgetSimulationVideo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43md\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnbTimesteps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdebug\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdebug\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "File \u001b[0;32m/master/code/lib/NNSimulator_2.py:221\u001b[0m, in \u001b[0;36mgetSimulationVideo\u001b[0;34m(model, initPos, nbTimesteps, initState, train, debug)\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\" \u001b[39;00m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;124;03mFunction to create a simulation from the model\u001b[39;00m\n\u001b[1;32m    205\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[38;5;124;03m    tensor of the different positions\u001b[39;00m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    219\u001b[0m simulator \u001b[38;5;241m=\u001b[39m NNSimulator(model)\n\u001b[0;32m--> 221\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43msimulator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunSim\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbTimesteps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitState\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitPos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdebug\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdebug\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    223\u001b[0m \u001b[38;5;66;03m#create_simulation_video_cv2(res, outputPath, fps = 10, size = (600,600))\u001b[39;00m\n\u001b[1;32m    225\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "File \u001b[0;32m/master/code/lib/NNSimulator_2.py:52\u001b[0m, in \u001b[0;36mNNSimulator.runSim\u001b[0;34m(self, T, state, pos, debug, train)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrunSim\u001b[39m(\u001b[38;5;28mself\u001b[39m, T, state, pos, debug \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, train \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m---> 52\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgenSim\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdebug\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdebug\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/master/code/lib/NNSimulator_2.py:126\u001b[0m, in \u001b[0;36mgenSim\u001b[0;34m(model, T, state, pos, train, debug)\u001b[0m\n\u001b[1;32m    121\u001b[0m     y \u001b[38;5;241m=\u001b[39m model(state)\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m OUTPUT_TYPE \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspeed\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;66;03m# Effect of boundary conditioned by previous position\u001b[39;00m\n\u001b[0;32m--> 126\u001b[0m     nPose \u001b[38;5;241m=\u001b[39m \u001b[43mhist\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\n\u001b[1;32m    127\u001b[0m     vNext \u001b[38;5;241m=\u001b[39m boundaryEffect(nPose, y, BOUNDARY )\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m OUTPUT_TYPE \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124macceleration\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'Tensor' and 'Data'"
     ]
    }
   ],
   "source": [
    "res = nnsim2.getSimulationData(mod, 450, data, i = 5, display =True, train = False).detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[-6.7076912e+00 -1.2044786e+01]\n",
      "  [ 1.0512610e+01  9.1655692e-03]\n",
      "  [ 5.0864558e+00 -2.5154173e+00]\n",
      "  ...\n",
      "  [-1.3638166e+01 -1.0110021e+01]\n",
      "  [ 1.9843127e+00 -1.3649011e+01]\n",
      "  [-5.9376211e+00  3.2489817e+00]]\n",
      "\n",
      " [[-7.8006296e+00 -1.2476010e+01]\n",
      "  [ 9.4459867e+00  5.9937894e-01]\n",
      "  [ 4.7045226e+00 -2.9519253e+00]\n",
      "  ...\n",
      "  [-1.3896918e+01 -1.0554628e+01]\n",
      "  [ 8.2406759e-01 -1.5228206e+01]\n",
      "  [-5.2568684e+00  3.5618536e+00]]\n",
      "\n",
      " [[-8.8935680e+00 -1.2907234e+01]\n",
      "  [ 8.3793631e+00  1.1895924e+00]\n",
      "  [ 4.3225894e+00 -3.3884332e+00]\n",
      "  ...\n",
      "  [-1.4155670e+01 -1.0999236e+01]\n",
      "  [-3.3617747e-01 -1.6807400e+01]\n",
      "  [-4.5761156e+00  3.8747256e+00]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[-1.9822952e+01 -3.4468464e+01]\n",
      "  [ 1.0512608e+01 -2.4779806e+01]\n",
      "  [-7.3591995e+01 -4.1801147e+01]\n",
      "  ...\n",
      "  [-1.1041113e+02 -3.0561951e+01]\n",
      "  [-3.9784512e+01  5.3013301e+00]\n",
      "  [-6.0397823e+01  9.6484818e+01]]\n",
      "\n",
      " [[-2.0915892e+01 -3.4037239e+01]\n",
      "  [ 9.4459839e+00 -2.5370020e+01]\n",
      "  [-7.3210060e+01 -4.1364639e+01]\n",
      "  ...\n",
      "  [-1.1015238e+02 -3.0117344e+01]\n",
      "  [-4.0944756e+01  6.8805251e+00]\n",
      "  [-6.1078575e+01  9.6171944e+01]]\n",
      "\n",
      " [[-2.2008831e+01 -3.3606014e+01]\n",
      "  [ 8.3793602e+00 -2.5960234e+01]\n",
      "  [-7.2828125e+01 -4.0928131e+01]\n",
      "  ...\n",
      "  [-1.0989363e+02 -2.9672737e+01]\n",
      "  [-4.2105000e+01  8.4597197e+00]\n",
      "  [-6.1759327e+01  9.5859070e+01]]]\n"
     ]
    }
   ],
   "source": [
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-6.7077e+00, -1.2045e+01],\n",
      "         [ 1.0513e+01,  9.1656e-03],\n",
      "         [ 5.0865e+00, -2.5154e+00],\n",
      "         ...,\n",
      "         [-1.3638e+01, -1.0110e+01],\n",
      "         [ 1.9843e+00, -1.3649e+01],\n",
      "         [-5.9376e+00,  3.2490e+00]],\n",
      "\n",
      "        [[-6.4566e+00, -1.1831e+01],\n",
      "         [ 9.4011e+00,  1.4728e+00],\n",
      "         [ 5.3145e+00, -1.6938e+00],\n",
      "         ...,\n",
      "         [-1.4538e+01, -1.0707e+01],\n",
      "         [ 2.6193e+00, -1.4153e+01],\n",
      "         [-5.7753e+00,  2.8642e+00]],\n",
      "\n",
      "        [[-5.4154e+00, -1.2934e+01],\n",
      "         [ 9.2004e+00,  9.4837e-01],\n",
      "         [ 3.9744e+00, -3.0634e-01],\n",
      "         ...,\n",
      "         [-1.4930e+01, -1.0657e+01],\n",
      "         [ 2.4416e+00, -1.5106e+01],\n",
      "         [-4.7184e+00,  3.3408e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 5.9869e+01, -5.5883e+01],\n",
      "         [-7.2395e+01,  1.1436e+02],\n",
      "         [-9.9907e+01,  9.8040e+01],\n",
      "         ...,\n",
      "         [-9.1500e+01, -6.2445e+01],\n",
      "         [-1.0935e+02, -6.5731e+01],\n",
      "         [ 7.0331e+01, -2.5590e+01]],\n",
      "\n",
      "        [[ 6.0143e+01, -5.5349e+01],\n",
      "         [-7.2653e+01,  1.1425e+02],\n",
      "         [-1.0027e+02,  9.7565e+01],\n",
      "         ...,\n",
      "         [-9.1378e+01, -6.2796e+01],\n",
      "         [-1.0971e+02, -6.5243e+01],\n",
      "         [ 6.9740e+01, -2.5694e+01]],\n",
      "\n",
      "        [[ 6.0417e+01, -5.4816e+01],\n",
      "         [-7.2911e+01,  1.1413e+02],\n",
      "         [-1.0028e+02,  9.7405e+01],\n",
      "         ...,\n",
      "         [-9.1255e+01, -6.3148e+01],\n",
      "         [-1.1007e+02, -6.4755e+01],\n",
      "         [ 6.9149e+01, -2.5797e+01]]], device='cuda:0', dtype=torch.float64)\n",
      "torch.Size([301, 100, 2])\n"
     ]
    }
   ],
   "source": [
    "print(res1[0])\n",
    "print(res1[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[-6.70769103e+00 -1.20447869e+01]\n",
      "  [ 1.05126102e+01  9.16556951e-03]\n",
      "  [ 5.08645587e+00 -2.51541739e+00]\n",
      "  ...\n",
      "  [-1.36381665e+01 -1.01100205e+01]\n",
      "  [ 1.98431264e+00 -1.36490104e+01]\n",
      "  [-5.93762117e+00  3.24898169e+00]]\n",
      "\n",
      " [[-6.45658512e+00 -1.18311370e+01]\n",
      "  [ 9.40114857e+00  1.47279832e+00]\n",
      "  [ 5.31446233e+00 -1.69377891e+00]\n",
      "  ...\n",
      "  [-1.45381082e+01 -1.07071892e+01]\n",
      "  [ 2.61932640e+00 -1.41529211e+01]\n",
      "  [-5.77534492e+00  2.86416658e+00]]\n",
      "\n",
      " [[-5.41538971e+00 -1.29339339e+01]\n",
      "  [ 9.20036558e+00  9.48371734e-01]\n",
      "  [ 3.97441838e+00 -3.06338833e-01]\n",
      "  ...\n",
      "  [-1.49304812e+01 -1.06573496e+01]\n",
      "  [ 2.44162826e+00 -1.51055446e+01]\n",
      "  [-4.71842688e+00  3.34077970e+00]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 5.98691838e+01 -5.58831319e+01]\n",
      "  [-7.23951659e+01  1.14358909e+02]\n",
      "  [-9.99069776e+01  9.80404868e+01]\n",
      "  ...\n",
      "  [-9.15002698e+01 -6.24448690e+01]\n",
      "  [-1.09351325e+02 -6.57308891e+01]\n",
      "  [ 7.03307823e+01 -2.55903050e+01]]\n",
      "\n",
      " [[ 6.01431380e+01 -5.53493257e+01]\n",
      "  [-7.26528529e+01  1.14245718e+02]\n",
      "  [-1.00272770e+02  9.75648866e+01]\n",
      "  ...\n",
      "  [-9.13776620e+01 -6.27964985e+01]\n",
      "  [-1.09710849e+02 -6.52429314e+01]\n",
      "  [ 6.97397271e+01 -2.56935221e+01]]\n",
      "\n",
      " [[ 6.04170923e+01 -5.48155195e+01]\n",
      "  [-7.29105399e+01  1.14132527e+02]\n",
      "  [-1.00277338e+02  9.74049327e+01]\n",
      "  ...\n",
      "  [-9.12550541e+01 -6.31481281e+01]\n",
      "  [-1.10070373e+02 -6.47549736e+01]\n",
      "  [ 6.91486719e+01 -2.57967393e+01]]]\n",
      "(301, 100, 2)\n"
     ]
    }
   ],
   "source": [
    "print(data[5:306, :, :])\n",
    "print(data[5:306, :, :].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.0738, -1.0999],\n",
      "         [ 0.6307,  0.8257],\n",
      "         [-0.7315,  1.3630],\n",
      "         ...,\n",
      "         [ 0.2377, -0.8401],\n",
      "         [-0.1215, -1.7602],\n",
      "         [-0.1529,  0.0554]],\n",
      "\n",
      "        [[ 0.7320, -0.9658],\n",
      "         [ 0.4175,  1.0415],\n",
      "         [-0.8946,  0.5743],\n",
      "         ...,\n",
      "         [-1.8204, -1.1515],\n",
      "         [ 0.6650,  0.2300],\n",
      "         [ 1.2095, -0.7060]],\n",
      "\n",
      "        [[ 2.1054, -0.6407],\n",
      "         [ 0.5988,  0.8087],\n",
      "         [-0.7992,  0.6345],\n",
      "         ...,\n",
      "         [-0.7873, -1.2387],\n",
      "         [ 0.6891, -0.2488],\n",
      "         [ 0.4422, -0.6524]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.2740,  0.5338],\n",
      "         [-0.2577, -0.1132],\n",
      "         [-0.3658, -0.4756],\n",
      "         ...,\n",
      "         [ 0.1226, -0.3516],\n",
      "         [-0.3595,  0.4880],\n",
      "         [-0.5911, -0.1032]],\n",
      "\n",
      "        [[ 0.2740,  0.5338],\n",
      "         [-0.2577, -0.1132],\n",
      "         [-0.3658, -0.4756],\n",
      "         ...,\n",
      "         [ 0.1226, -0.3516],\n",
      "         [-0.3595,  0.4880],\n",
      "         [-0.5911, -0.1032]],\n",
      "\n",
      "        [[ 0.2740,  0.5338],\n",
      "         [-0.2577, -0.1132],\n",
      "         [-0.3658, -0.4756],\n",
      "         ...,\n",
      "         [ 0.1226, -0.3516],\n",
      "         [-0.3595,  0.4880],\n",
      "         [-0.5911, -0.1032]]], device='cuda:0', dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "print(res1[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         ...,\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         ...,\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         ...,\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         ...,\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         ...,\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         ...,\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]]], dtype=torch.float64)\n",
      "tensor(0., dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "print(res1[1].cpu() - speeds[:300])\n",
    "print(torch.sum(res1[1].cpu() - speeds[:300]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "comp = res1[0].cpu().detach().numpy()\n",
    "s = speeds.cpu().detach().numpy()\n",
    "i = 1\n",
    "plt.scatter(data[5 + i, :10, 0], data[5 + i, :10, 0], color = 'red',alpha = 0.4)\n",
    "plt.scatter(comp[i, :10, 0], comp[i, :10, 0], color = 'green',alpha = 0.4)\n",
    "#plt.scatter(data[5 + i - 1, :10, 0] + s[i-1, :10, 0], data[5 + i - 1, :10, 0] + s[i-1, :10, 1], color = 'blue',alpha = 0.4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp = res1[0].cpu().detach().numpy()\n",
    "cwd = os.getcwd()\n",
    "p = '/master/tests/data/comp.mp4'\n",
    "vidParams = disp.videoParameters(p)\n",
    "import cv2\n",
    "\n",
    "def compareVideo(data, ground_truth, video_params, bounds=None):\n",
    "    \"\"\"\n",
    "    Creates an MP4 video from a PyTorch tensor representing cell movements using cv2,\n",
    "    and includes ground truth data visualized in a different color.\n",
    "\n",
    "    Parameters:\n",
    "    - data: A PyTorch tensor of shape [T, N, 2], where T is the number of timesteps,\n",
    "            N is the number of cells, and 2 corresponds to the coordinates (x, y).\n",
    "    - ground_truth: A PyTorch tensor of shape [T, N, 2], same format as data, representing the ground truth.\n",
    "    - video_params: An instance of videoParameters class containing video settings.\n",
    "    - bounds: Tuple of ((min_x, max_x), (min_y, max_y)) specifying the bounds for the positions.\n",
    "              If None, it uses the minimum and maximum values from the data.\n",
    "    \"\"\"\n",
    "    \n",
    "    if bounds:\n",
    "        min_x, max_x = bounds[0]\n",
    "        min_y, max_y = bounds[1]\n",
    "    else:\n",
    "        min_x, max_x = min(data.min(), ground_truth.min()), max(data.max(), ground_truth.max())\n",
    "        min_y, max_y = min(data.min(), ground_truth.min()), max(data.max(), ground_truth.max())\n",
    "\n",
    "    # Normalize coordinates to fit within the video frame size\n",
    "    data[:, :, 0] = (data[:, :, 0] - min_x) / (max_x - min_x) * (video_params.size[0] - 1)\n",
    "    data[:, :, 1] = (data[:, :, 1] - min_y) / (max_y - min_y) * (video_params.size[1] - 1)\n",
    "    ground_truth[:, :, 0] = (ground_truth[:, :, 0] - min_x) / (max_x - min_x) * (video_params.size[0] - 1)\n",
    "    ground_truth[:, :, 1] = (ground_truth[:, :, 1] - min_y) / (max_y - min_y) * (video_params.size[1] - 1)\n",
    "\n",
    "    # Define the codec and create VideoWriter object\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # Be sure to use lowercase\n",
    "    out = cv2.VideoWriter(video_params.path, fourcc, video_params.fps, video_params.size)\n",
    "\n",
    "    # Colors (BGR format) and radius\n",
    "    pred_color = (0, 255, 0)  # Green for predictions\n",
    "    gt_color = (0, 0, 255)  # Red for ground truth\n",
    "\n",
    "    for i in range(data.shape[0]):\n",
    "        frame = np.zeros((video_params.size[1], video_params.size[0], 3), dtype=np.uint8)\n",
    "        \n",
    "        # Draw ground truth and predictions\n",
    "        for (x, y), (gt_x, gt_y) in zip(data[i], ground_truth[i]):\n",
    "            cv2.circle(frame, (int(x), int(y)), radius=5, color=pred_color, thickness=-1)\n",
    "            cv2.circle(frame, (int(gt_x), int(gt_y)), radius=2, color=gt_color, thickness=-1)\n",
    "        \n",
    "        # Draw legend\n",
    "        cv2.rectangle(frame, (10, 10), (10 + 20, 30), pred_color, -1)  # Prediction color box\n",
    "        cv2.rectangle(frame, (10, 40), (10 + 20, 60), gt_color, -1)  # Ground truth color box\n",
    "        cv2.putText(frame, 'Prediction', (35, 25), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1, cv2.LINE_AA)\n",
    "        cv2.putText(frame, 'Ground Truth', (35, 55), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1, cv2.LINE_AA)\n",
    "\n",
    "        out.write(frame)\n",
    "\n",
    "    out.release()\n",
    "\n",
    "compareVideo(comp.copy(), data[5:306,:, :].copy(), vidParams,bounds=((-140, 140), (-140, 140)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'p' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/master/tests/data/vid_test.mp4\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mp\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'p' is not defined"
     ]
    }
   ],
   "source": [
    "print(os.path.exists('/master/tests/data/vid_test.mp4'))\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "p = '/master/tests/data/vid_test.mp4'\n",
    "vidParams = disp.videoParameters(p)\n",
    "\n",
    "disp.create_simulation_video_cv2(res1[0].cpu().numpy().copy(), vidParams, ((-140, 140), (-140, 140)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "p = '/master/tests/data/vid_test_d.mp4'\n",
    "vidParams = disp.videoParameters(p)\n",
    "\n",
    "disp.create_simulation_video_cv2(data[5:, :, :].copy(), vidParams, ((-140, 140), (-140, 140)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get different kinds of simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lim = 0.85 * 100\n",
    "\n",
    "xPos = np.linspace(-lim, lim, 10)\n",
    "yPos = np.linspace(-lim, lim, 10)\n",
    "gridX, gridY = np.meshgrid(xPos, yPos)\n",
    "delta = np.random.uniform(0, 7, gridX.shape + (2,))\n",
    "\n",
    "gridX2 = gridX + delta[:, :, 0]\n",
    "gridY2 = gridY + delta[:, :, 1]\n",
    "\n",
    "pos = np.stack([gridX.ravel(), gridY.ravel()], axis=1)\n",
    "pos_perturbed = np.stack([gridX2.ravel(), gridY2.ravel()], axis=1)\n",
    "\n",
    "pos = np.concatenate([pos, pos_perturbed], axis=0)\n",
    "\n",
    "angles = np.random.rand(pos.shape[0]) * 2 * np.pi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v0:60, tau:3.5, k:70, epsilon:0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:10<00:00, 94.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v0:60, tau:3.5, k:70, epsilon:0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:09<00:00, 100.07it/s]\n"
     ]
    }
   ],
   "source": [
    "nb = 200\n",
    "v0 = [25, 60, 30, 7]\n",
    "k = [25, 70, 50, 40]\n",
    "tau = [2.5, 3.5, 2.5, 1.5]\n",
    "epsilon = [0.5, 0.5, 0.5, 0.5]\n",
    "dt = [0.01, 0.001]\n",
    "\n",
    "\n",
    "path = '/master/tests/data/simulation_types'\n",
    "\n",
    "\n",
    "for i in range(len(dt)):\n",
    "    data = sim.compute_main(nb, (v0[1], tau[1], k[1], epsilon[1]), 120, T = 1000, dt = dt[i], initialization = (pos, angles), seed=np.random.randint(1, 1015151231))[0]\n",
    "    #data = sim2.compute_main(nb, (v0[i], tau[i], k[i], epsilon[i]), 120, T = 1000, seed=np.random.randint(1, 1015151231))[0]\n",
    "    #data = sim3.compute_main(nb, (v0[i], tau[i], k[i], epsilon[i]), 120, T = 1000, seed=np.random.randint(1, 1015151231))[0]\n",
    "\n",
    "    name = f\"v0_{v0[1]}_tau_{tau[1]}_k_{k[1]}_dt_{dt[i]}.mp4\"\n",
    "\n",
    "    p = os.path.join(path, name)\n",
    "    vidParams = disp.videoParameters(p)\n",
    "\n",
    "    disp.create_simulation_video_cv2(data.copy(), vidParams, ((-140, 140), (-140, 140)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def videoGraphBase(data, edge_indices, video_params, bounds=None):\n",
    "    \"\"\"\n",
    "    Creates an MP4 video from a PyTorch tensor representing graph nodes and edges using cv2,\n",
    "    based on specified video parameters and position bounds.\n",
    "\n",
    "    Parameters:\n",
    "    - data: A PyTorch tensor of shape [T, N, 2], where T is the number of timesteps,\n",
    "            N is the number of nodes, and 2 corresponds to the coordinates (x, y).\n",
    "    - edge_indices: A PyTorch tensor of shape [2, E], where E is the number of edges,\n",
    "                    and each column is a pair of indices (start_node, end_node).\n",
    "    - video_params: An instance of VideoParameters class containing video settings.\n",
    "    - bounds: Tuple of ((min_x, max_x), (min_y, max_y)) specifying the bounds for the positions.\n",
    "              If None, uses the minimum and maximum values from the data.\n",
    "    \"\"\"\n",
    "    if bounds:\n",
    "        min_x, max_x = bounds[0]\n",
    "        min_y, max_y = bounds[1]\n",
    "    else:\n",
    "        min_x, max_x = data[:, :, 0].min(), data[:, :, 0].max()\n",
    "        min_y, max_y = data[:, :, 1].min(), data[:, :, 1].max()\n",
    "\n",
    "    # Normalize coordinates to fit within the video frame size\n",
    "    data[:, :, 0] = (data[:, :, 0] - min_x) / (max_x - min_x) * (video_params.size[0] - 1)\n",
    "    data[:, :, 1] = (data[:, :, 1] - min_y) / (max_y - min_y) * (video_params.size[1] - 1)\n",
    "\n",
    "    # Define the codec and create VideoWriter object\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # Be sure to use lowercase\n",
    "    out = cv2.VideoWriter(video_params.path, fourcc, video_params.fps, video_params.size)\n",
    "\n",
    "    for i in range(data.shape[0]):\n",
    "        frame = np.zeros((video_params.size[1], video_params.size[0], 3), dtype=np.uint8)\n",
    "\n",
    "        # Draw nodes\n",
    "        for x, y in data[i].int().numpy():\n",
    "            cv2.circle(frame, (x, y), 3, (0, 255, 0), -1)\n",
    "\n",
    "        # Draw edges\n",
    "        for start_node, end_node in edge_indices[i].t().numpy():\n",
    "            pt1 = tuple(data[i, start_node].int().numpy())\n",
    "            pt2 = tuple(data[i, end_node].int().numpy())\n",
    "            cv2.line(frame, pt1, pt2, (0, 0, 255), 2)\n",
    "\n",
    "\n",
    "        out.write(frame)\n",
    "\n",
    "    out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(600, 600)\n"
     ]
    }
   ],
   "source": [
    "print(vidParams.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v0:60, tau:3.5, k:70, epsilon:0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:09<00:00, 101.97it/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'clone'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 24\u001b[0m\n\u001b[1;32m     20\u001b[0m vidParams \u001b[38;5;241m=\u001b[39m disp\u001b[38;5;241m.\u001b[39mvideoParameters(p)\n\u001b[1;32m     22\u001b[0m x, y, attr, inds \u001b[38;5;241m=\u001b[39m ft\u001b[38;5;241m.\u001b[39mprocessSimulation(data)\n\u001b[0;32m---> 24\u001b[0m disp\u001b[38;5;241m.\u001b[39mvideoGraphBase(\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclone\u001b[49m(), inds\u001b[38;5;241m.\u001b[39mclone(), vidParams, ((\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m140\u001b[39m, \u001b[38;5;241m140\u001b[39m), (\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m140\u001b[39m, \u001b[38;5;241m140\u001b[39m)))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'clone'"
     ]
    }
   ],
   "source": [
    "nb = 200\n",
    "v0 = [25, 60, 30, 7]\n",
    "k = [25, 70, 50, 40]\n",
    "tau = [2.5, 3.5, 2.5, 1.5]\n",
    "epsilon = [0.5, 0.5, 0.5, 0.5]\n",
    "dt = [0.01, 0.001]\n",
    "\n",
    "\n",
    "path = '/master/tests/data/simulation_types'\n",
    "\n",
    "\n",
    "for i in range(len(dt)):\n",
    "    data = sim.compute_main(nb, (v0[1], tau[1], k[1], epsilon[1]), 120, T = 1000, dt = dt[i], initialization = (pos, angles), seed=np.random.randint(1, 1015151231))[0]\n",
    "    #data = sim2.compute_main(nb, (v0[i], tau[i], k[i], epsilon[i]), 120, T = 1000, seed=np.random.randint(1, 1015151231))[0]\n",
    "    #data = sim3.compute_main(nb, (v0[i], tau[i], k[i], epsilon[i]), 120, T = 1000, seed=np.random.randint(1, 1015151231))[0]\n",
    "\n",
    "    name = f\"v0_{v0[1]}_tau_{tau[1]}_k_{k[1]}_dt_{dt[i]}_graph.mp4\"\n",
    "\n",
    "    p = os.path.join(path, name)\n",
    "    vidParams = disp.videoParameters(p)\n",
    "\n",
    "    inds = []\n",
    "    radius = np.ones(data.shape[1]) * 1\n",
    "\n",
    "    for i in range(data.shape[0]):\n",
    "        inds.append(ft.optimized_getGraph(data[t], radius))\n",
    "\n",
    "    x, y, attr, inds = ft.processSimulation(data)\n",
    "\n",
    "    disp.videoGraphBase(x.clone(), inds.clone(), vidParams, ((-140, 140), (-140, 140)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
